{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/megh/AI/Projects/Semantic_Segmentation_for_self_driving_cars'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-28 13:14:47.119612: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 13:14:47.755244: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.components.data_preparation import DataIngestion\n",
    "from src.components.data_preprocesing import DataPreprocessing\n",
    "from src.components.callbacks import PrepareCallback\n",
    "from src.components.model import PrepareModel\n",
    "from src.config.configuration import ConfigurationManager\n",
    "from src.entity.config_entity import DataIngestionConfig, PrepareCallbackConfig, PrepareModelConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.entity.config_entity import DataPreprocessingConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-28 13:14:57,369: INFO: common: yaml fileconfig.yamlloaded Successfully]\n",
      "[2023-09-28 13:14:57,373: INFO: common: yaml fileparams.yamlloaded Successfully]\n",
      "[2023-09-28 13:14:57,374: INFO: common: created directory at:artifacts]\n",
      "[2023-09-28 13:14:57,375: INFO: common: created directory at:/media/Ubuntu/meg/mlprojects/Semantic_Segmentation_for_self_driving_cars/archive]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-28 13:14:58.983544: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-09-28 13:14:58.983589: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: megh\n",
      "2023-09-28 13:14:58.983594: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: megh\n",
      "2023-09-28 13:14:58.983718: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 535.113.1\n",
      "2023-09-28 13:14:58.983732: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 535.86.10\n",
      "2023-09-28 13:14:58.983736: E tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:312] kernel version 535.86.10 does not match DSO version 535.113.1 -- cannot find working devices in this configuration\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_data_config = config.get_data_ingestion_config()\n",
    "\n",
    "    prepare_dataset = DataIngestion(config=prepare_data_config)\n",
    "    imgs_list, masks_list = prepare_dataset.prepare_data()\n",
    "\n",
    "    preprocessing_config = config.get_data_processing_config()\n",
    "    preprocessing = DataPreprocessing(preprocessing_config,imgs_list, masks_list)\n",
    "    train, val = preprocessing.data_preprocessing()\n",
    "\n",
    "except Exception as e:\n",
    "    raise e\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-28 13:15:21,974: INFO: common: yaml fileconfig.yamlloaded Successfully]\n",
      "[2023-09-28 13:15:21,977: INFO: common: yaml fileparams.yamlloaded Successfully]\n",
      "[2023-09-28 13:15:21,978: INFO: common: created directory at:artifacts]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 192, 256, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 192, 256, 32)         896       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 192, 256, 32)         128       ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)     (None, 192, 256, 32)         0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 192, 256, 32)         9248      ['leaky_re_lu[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 192, 256, 32)         128       ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 192, 256, 32)         0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 96, 128, 32)          0         ['leaky_re_lu_1[0][0]']       \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 96, 128, 64)          18496     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 96, 128, 64)          256       ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 96, 128, 64)          0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 96, 128, 64)          36928     ['leaky_re_lu_2[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 96, 128, 64)          256       ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 96, 128, 64)          0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 48, 64, 64)           0         ['leaky_re_lu_3[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 48, 64, 128)          73856     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 48, 64, 128)          512       ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 48, 64, 128)          0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 48, 64, 128)          147584    ['leaky_re_lu_4[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 48, 64, 128)          512       ['conv2d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 48, 64, 128)          0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 24, 32, 128)          0         ['leaky_re_lu_5[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 24, 32, 256)          295168    ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 24, 32, 256)          1024      ['conv2d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 24, 32, 256)          0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 24, 32, 256)          590080    ['leaky_re_lu_6[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 24, 32, 256)          1024      ['conv2d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 24, 32, 256)          0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 24, 32, 256)          0         ['leaky_re_lu_7[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 12, 16, 256)          0         ['dropout[0][0]']             \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 12, 16, 512)          1180160   ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 12, 16, 512)          2048      ['conv2d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 12, 16, 512)          0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 12, 16, 512)          2359808   ['leaky_re_lu_8[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 12, 16, 512)          2048      ['conv2d_9[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 12, 16, 512)          0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 12, 16, 512)          0         ['leaky_re_lu_9[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTr  (None, 24, 32, 256)          1179904   ['dropout_1[0][0]']           \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)      (None, 24, 32, 512)          0         ['conv2d_transpose[0][0]',    \n",
      "                                                                     'dropout[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 24, 32, 256)          1179904   ['tf.concat[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 24, 32, 256)          1024      ['conv2d_10[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 24, 32, 256)          0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 24, 32, 256)          590080    ['leaky_re_lu_10[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 24, 32, 256)          1024      ['conv2d_11[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 24, 32, 256)          0         ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2D  (None, 48, 64, 128)          295040    ['leaky_re_lu_11[0][0]']      \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)    (None, 48, 64, 256)          0         ['conv2d_transpose_1[0][0]',  \n",
      "                                                                     'leaky_re_lu_5[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 48, 64, 128)          295040    ['tf.concat_1[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 48, 64, 128)          512       ['conv2d_12[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 48, 64, 128)          0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 48, 64, 128)          147584    ['leaky_re_lu_12[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 48, 64, 128)          512       ['conv2d_13[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 48, 64, 128)          0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2D  (None, 96, 128, 64)          73792     ['leaky_re_lu_13[0][0]']      \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " tf.concat_2 (TFOpLambda)    (None, 96, 128, 128)         0         ['conv2d_transpose_2[0][0]',  \n",
      "                                                                     'leaky_re_lu_3[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 96, 128, 64)          73792     ['tf.concat_2[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 96, 128, 64)          256       ['conv2d_14[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_14 (LeakyReLU)  (None, 96, 128, 64)          0         ['batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 96, 128, 64)          36928     ['leaky_re_lu_14[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, 96, 128, 64)          256       ['conv2d_15[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 96, 128, 64)          0         ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2D  (None, 192, 256, 32)         18464     ['leaky_re_lu_15[0][0]']      \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " tf.concat_3 (TFOpLambda)    (None, 192, 256, 64)         0         ['conv2d_transpose_3[0][0]',  \n",
      "                                                                     'leaky_re_lu_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 192, 256, 32)         18464     ['tf.concat_3[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (None, 192, 256, 32)         128       ['conv2d_16[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 192, 256, 32)         0         ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 192, 256, 32)         9248      ['leaky_re_lu_16[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (None, 192, 256, 32)         128       ['conv2d_17[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 192, 256, 32)         0         ['batch_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 192, 256, 32)         9248      ['leaky_re_lu_17[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_18 (Ba  (None, 192, 256, 32)         128       ['conv2d_18[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 192, 256, 32)         0         ['batch_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, 192, 256, 13)         429       ['leaky_re_lu_18[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_19 (Ba  (None, 192, 256, 13)         52        ['conv2d_19[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 192, 256, 13)         0         ['batch_normalization_19[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8652097 (33.01 MB)\n",
      "Trainable params: 8646119 (32.98 MB)\n",
      "Non-trainable params: 5978 (23.35 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_model_config = config.get_prepare_model_config()\n",
    "    prepare_model = PrepareModel(prepare_model_config)\n",
    "    model = prepare_model.unet_model()\n",
    "    model.summary()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainingConfig:\n",
    "    epochs: int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.constants import *\n",
    "from src.utils.common import read_yaml, create_directories\n",
    "from box import ConfigBox\n",
    "from src import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-28 13:18:27,293: INFO: common: yaml fileconfig.yamlloaded Successfully]\n",
      "[2023-09-28 13:18:27,295: INFO: common: yaml fileparams.yamlloaded Successfully]\n",
      "[2023-09-28 13:18:27,297: INFO: common: created directory at:artifacts]\n",
      "[2023-09-28 13:18:27,298: INFO: common: created directory at:artifacts/callbacks]\n",
      "[2023-09-28 13:18:27,299: INFO: common: created directory at:artifacts/callbacks/checkpoints]\n",
      "[2023-09-28 13:18:27,300: INFO: common: created directory at:artifacts/callbacks/tensorboard_log_dir]\n",
      "artifacts/callbacks/tensorboard_log_dir/tb_logs_at_2023-09-28-13-18-27\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_callbacks_config= config.get_prepare_callback_config()\n",
    "    prepare_callbacks= PrepareCallback(config = prepare_callbacks_config)\n",
    "    callback_list = prepare_callbacks.get_tb_ckpt_callbacks()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = model.compile(optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "                    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.1'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0.2392157  0.38823533 0.5686275 ]\n",
      "   [0.2392157  0.39607847 0.5686275 ]\n",
      "   [0.2392157  0.39607847 0.5686275 ]\n",
      "   ...\n",
      "   [0.6431373  0.6156863  0.5254902 ]\n",
      "   [0.6313726  0.60784316 0.5137255 ]\n",
      "   [0.62352943 0.6        0.5058824 ]]\n",
      "\n",
      "  [[0.2392157  0.39607847 0.5686275 ]\n",
      "   [0.2392157  0.38823533 0.5686275 ]\n",
      "   [0.2392157  0.38823533 0.5686275 ]\n",
      "   ...\n",
      "   [0.62352943 0.6        0.5058824 ]\n",
      "   [0.6117647  0.5882353  0.49411768]\n",
      "   [0.60784316 0.5882353  0.49411768]]\n",
      "\n",
      "  [[0.2392157  0.38823533 0.5686275 ]\n",
      "   [0.2392157  0.39607847 0.57254905]\n",
      "   [0.2392157  0.39607847 0.57254905]\n",
      "   ...\n",
      "   [0.5921569  0.5647059  0.47058827]\n",
      "   [0.5803922  0.5529412  0.45882356]\n",
      "   [0.59607846 0.5686275  0.4784314 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.0509804 ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.0509804  0.0509804  0.        ]\n",
      "   [0.0509804  0.0509804  0.        ]]\n",
      "\n",
      "  [[0.         0.         0.0509804 ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.0509804 ]\n",
      "   ...\n",
      "   [0.0509804  0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.0509804 ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.0509804 ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.69803923 0.7058824  0.70980394]\n",
      "   [0.7019608  0.70980394 0.7137255 ]\n",
      "   [0.7058824  0.70980394 0.7137255 ]\n",
      "   ...\n",
      "   [0.6745098  0.6862745  0.6901961 ]\n",
      "   [0.6745098  0.6862745  0.6901961 ]\n",
      "   [0.67058825 0.68235296 0.6862745 ]]\n",
      "\n",
      "  [[0.7019608  0.70980394 0.7137255 ]\n",
      "   [0.7019608  0.70980394 0.7137255 ]\n",
      "   [0.7058824  0.7137255  0.7137255 ]\n",
      "   ...\n",
      "   [0.6745098  0.6862745  0.6901961 ]\n",
      "   [0.6745098  0.6862745  0.6901961 ]\n",
      "   [0.6745098  0.6862745  0.6901961 ]]\n",
      "\n",
      "  [[0.7019608  0.70980394 0.7137255 ]\n",
      "   [0.7019608  0.70980394 0.7137255 ]\n",
      "   [0.7058824  0.7137255  0.7137255 ]\n",
      "   ...\n",
      "   [0.6745098  0.6862745  0.69411767]\n",
      "   [0.6745098  0.6862745  0.69411767]\n",
      "   [0.6745098  0.6862745  0.6901961 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0509804  0.0509804  0.0509804 ]\n",
      "   [0.08627451 0.08627451 0.08627451]\n",
      "   [0.0509804  0.0509804  0.0509804 ]\n",
      "   ...\n",
      "   [0.08627451 0.08627451 0.08627451]\n",
      "   [0.08627451 0.08627451 0.10980393]\n",
      "   [0.0509804  0.0509804  0.0509804 ]]\n",
      "\n",
      "  [[0.08627451 0.08627451 0.08627451]\n",
      "   [0.0509804  0.0509804  0.08627451]\n",
      "   [0.08627451 0.08627451 0.08627451]\n",
      "   ...\n",
      "   [0.08627451 0.08627451 0.08627451]\n",
      "   [0.0509804  0.0509804  0.08627451]\n",
      "   [0.08627451 0.08627451 0.08627451]]\n",
      "\n",
      "  [[0.08627451 0.08627451 0.08627451]\n",
      "   [0.08627451 0.08627451 0.08627451]\n",
      "   [0.08627451 0.08627451 0.08627451]\n",
      "   ...\n",
      "   [0.08627451 0.08627451 0.08627451]\n",
      "   [0.0509804  0.08627451 0.08627451]\n",
      "   [0.08627451 0.08627451 0.08627451]]]\n",
      "\n",
      "\n",
      " [[[0.42352945 0.5058824  0.58431375]\n",
      "   [0.42352945 0.5058824  0.58431375]\n",
      "   [0.427451   0.50980395 0.5882353 ]\n",
      "   ...\n",
      "   [0.5019608  0.5568628  0.6117647 ]\n",
      "   [0.4901961  0.54901963 0.60784316]\n",
      "   [0.4784314  0.5411765  0.6       ]]\n",
      "\n",
      "  [[0.40000004 0.49411768 0.58431375]\n",
      "   [0.427451   0.50980395 0.5882353 ]\n",
      "   [0.427451   0.50980395 0.5882353 ]\n",
      "   ...\n",
      "   [0.49803925 0.5529412  0.60784316]\n",
      "   [0.4901961  0.54901963 0.60784316]\n",
      "   [0.47450984 0.5411765  0.6039216 ]]\n",
      "\n",
      "  [[0.427451   0.50980395 0.5882353 ]\n",
      "   [0.427451   0.50980395 0.5882353 ]\n",
      "   [0.43137258 0.5137255  0.5921569 ]\n",
      "   ...\n",
      "   [0.49411768 0.5529412  0.60784316]\n",
      "   [0.48627454 0.54509807 0.60784316]\n",
      "   [0.47058827 0.53333336 0.6       ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.0509804  0.0509804 ]\n",
      "   [0.         0.         0.0509804 ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.0509804 ]\n",
      "   [0.         0.         0.0509804 ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.7058824  0.7137255  0.7176471 ]\n",
      "   [0.70980394 0.7137255  0.72156864]\n",
      "   [0.70980394 0.7176471  0.72156864]\n",
      "   ...\n",
      "   [0.6745098  0.6862745  0.6901961 ]\n",
      "   [0.6745098  0.6862745  0.6901961 ]\n",
      "   [0.6666667  0.6784314  0.6862745 ]]\n",
      "\n",
      "  [[0.7058824  0.7137255  0.7176471 ]\n",
      "   [0.70980394 0.7176471  0.72156864]\n",
      "   [0.7137255  0.7176471  0.72156864]\n",
      "   ...\n",
      "   [0.6745098  0.6862745  0.6901961 ]\n",
      "   [0.6745098  0.6862745  0.6901961 ]\n",
      "   [0.67058825 0.68235296 0.6862745 ]]\n",
      "\n",
      "  [[0.7058824  0.7137255  0.7137255 ]\n",
      "   [0.7058824  0.7137255  0.72156864]\n",
      "   [0.70980394 0.7176471  0.72156864]\n",
      "   ...\n",
      "   [0.6745098  0.6862745  0.6901961 ]\n",
      "   [0.67058825 0.68235296 0.6862745 ]\n",
      "   [0.6666667  0.6784314  0.6862745 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.0509804 ]\n",
      "   [0.0509804  0.0509804  0.08627451]\n",
      "   [0.0509804  0.0509804  0.0509804 ]\n",
      "   ...\n",
      "   [0.08627451 0.08627451 0.08627451]\n",
      "   [0.08627451 0.08627451 0.08627451]\n",
      "   [0.0509804  0.0509804  0.0509804 ]]\n",
      "\n",
      "  [[0.08627451 0.08627451 0.08627451]\n",
      "   [0.0509804  0.0509804  0.0509804 ]\n",
      "   [0.08627451 0.08627451 0.08627451]\n",
      "   ...\n",
      "   [0.08627451 0.08627451 0.10980393]\n",
      "   [0.08627451 0.08627451 0.08627451]\n",
      "   [0.08627451 0.08627451 0.08627451]]\n",
      "\n",
      "  [[0.0509804  0.0509804  0.08627451]\n",
      "   [0.08627451 0.08627451 0.08627451]\n",
      "   [0.0509804  0.0509804  0.0509804 ]\n",
      "   ...\n",
      "   [0.08627451 0.08627451 0.08627451]\n",
      "   [0.08627451 0.08627451 0.08627451]\n",
      "   [0.08627451 0.08627451 0.08627451]]]\n",
      "\n",
      "\n",
      " [[[0.5058824  0.5568628  0.60784316]\n",
      "   [0.50980395 0.56078434 0.60784316]\n",
      "   [0.52156866 0.57254905 0.61960787]\n",
      "   ...\n",
      "   [0.41176474 0.5019608  0.58431375]\n",
      "   [0.41176474 0.5019608  0.5803922 ]\n",
      "   [0.4039216  0.49803925 0.5803922 ]]\n",
      "\n",
      "  [[0.5137255  0.5647059  0.6117647 ]\n",
      "   [0.5176471  0.5686275  0.6156863 ]\n",
      "   [0.52156866 0.57254905 0.61960787]\n",
      "   ...\n",
      "   [0.4156863  0.5058824  0.5882353 ]\n",
      "   [0.41176474 0.5058824  0.58431375]\n",
      "   [0.41176474 0.5019608  0.5803922 ]]\n",
      "\n",
      "  [[0.5137255  0.5647059  0.6117647 ]\n",
      "   [0.52156866 0.57254905 0.61960787]\n",
      "   [0.52156866 0.57254905 0.61960787]\n",
      "   ...\n",
      "   [0.4156863  0.50980395 0.5882353 ]\n",
      "   [0.4156863  0.50980395 0.5882353 ]\n",
      "   [0.4156863  0.5058824  0.58431375]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.57254905 0.5137255  0.45098042]\n",
      "   [0.5686275  0.5058824  0.44705886]\n",
      "   [0.5686275  0.50980395 0.45098042]\n",
      "   ...\n",
      "   [0.5921569  0.5254902  0.45882356]\n",
      "   [0.5882353  0.5254902  0.45882356]\n",
      "   [0.58431375 0.52156866 0.45098042]]\n",
      "\n",
      "  [[0.57254905 0.50980395 0.45098042]\n",
      "   [0.57254905 0.50980395 0.45098042]\n",
      "   [0.57254905 0.50980395 0.45098042]\n",
      "   ...\n",
      "   [0.58431375 0.52156866 0.45882356]\n",
      "   [0.58431375 0.52156866 0.45882356]\n",
      "   [0.5882353  0.5254902  0.45882356]]\n",
      "\n",
      "  [[0.5764706  0.5137255  0.45098042]\n",
      "   [0.57254905 0.5137255  0.45882356]\n",
      "   [0.5686275  0.50980395 0.45098042]\n",
      "   ...\n",
      "   [0.5803922  0.52156866 0.45882356]\n",
      "   [0.5882353  0.5254902  0.46274513]\n",
      "   [0.57254905 0.5176471  0.454902  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.28627452 0.20784315 0.16470589]\n",
      "   [0.27058825 0.19607845 0.14901961]\n",
      "   [0.25882354 0.19607845 0.14901961]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.0509804  0.0509804  0.        ]\n",
      "   [0.0509804  0.0509804  0.0509804 ]]\n",
      "\n",
      "  [[0.20784315 0.14901961 0.13333334]\n",
      "   [0.20784315 0.14901961 0.10980393]\n",
      "   [0.20784315 0.14901961 0.10980393]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.0509804  0.0509804  0.        ]\n",
      "   [0.0509804  0.0509804  0.0509804 ]]\n",
      "\n",
      "  [[0.14901961 0.10980393 0.08627451]\n",
      "   [0.16470589 0.10980393 0.08627451]\n",
      "   [0.14901961 0.10980393 0.08627451]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.0509804  0.0509804  0.0509804 ]\n",
      "   [0.         0.         0.        ]]]], shape=(64, 192, 256, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 1]\n",
      "   [ 1]\n",
      "   [ 1]]\n",
      "\n",
      "  [[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 1]\n",
      "   [ 1]\n",
      "   [ 1]]\n",
      "\n",
      "  [[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 1]\n",
      "   [ 1]\n",
      "   [ 1]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]]\n",
      "\n",
      "\n",
      " [[[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  [[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  [[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]]\n",
      "\n",
      "\n",
      " [[[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  [[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  [[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  [[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  [[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]]\n",
      "\n",
      "\n",
      " [[[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  [[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  [[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]]\n",
      "\n",
      "\n",
      " [[[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  [[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  [[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]]], shape=(64, 192, 256, 1), dtype=uint8)\n",
      "tf.Tensor(\n",
      "[[[[0.41176474 0.49803925 0.5764706 ]\n",
      "   [0.41176474 0.5019608  0.5764706 ]\n",
      "   [0.4156863  0.5019608  0.5803922 ]\n",
      "   ...\n",
      "   [0.41176474 0.5058824  0.58431375]\n",
      "   [0.41176474 0.5019608  0.58431375]\n",
      "   [0.41176474 0.5019608  0.58431375]]\n",
      "\n",
      "  [[0.4156863  0.5019608  0.5803922 ]\n",
      "   [0.4156863  0.5058824  0.5803922 ]\n",
      "   [0.4156863  0.5019608  0.5803922 ]\n",
      "   ...\n",
      "   [0.4156863  0.5058824  0.58431375]\n",
      "   [0.4156863  0.5058824  0.58431375]\n",
      "   [0.4156863  0.5058824  0.58431375]]\n",
      "\n",
      "  [[0.4156863  0.5019608  0.5803922 ]\n",
      "   [0.42352945 0.5058824  0.58431375]\n",
      "   [0.4156863  0.5058824  0.58431375]\n",
      "   ...\n",
      "   [0.4156863  0.50980395 0.5882353 ]\n",
      "   [0.4156863  0.5058824  0.58431375]\n",
      "   [0.4156863  0.5058824  0.58431375]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.0509804 ]\n",
      "   ...\n",
      "   [0.0509804  0.0509804  0.08627451]\n",
      "   [0.08627451 0.08627451 0.10980393]\n",
      "   [0.0509804  0.0509804  0.08627451]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.0509804 ]\n",
      "   [0.         0.         0.0509804 ]\n",
      "   ...\n",
      "   [0.0509804  0.08627451 0.10980393]\n",
      "   [0.         0.0509804  0.0509804 ]\n",
      "   [0.0509804  0.08627451 0.08627451]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.0509804  0.0509804 ]\n",
      "   [0.         0.0509804  0.0509804 ]\n",
      "   ...\n",
      "   [0.0509804  0.0509804  0.08627451]\n",
      "   [0.0509804  0.0509804  0.08627451]\n",
      "   [0.         0.0509804  0.0509804 ]]]\n",
      "\n",
      "\n",
      " [[[0.6392157  0.6509804  0.654902  ]\n",
      "   [0.6392157  0.6509804  0.654902  ]\n",
      "   [0.6431373  0.654902   0.654902  ]\n",
      "   ...\n",
      "   [0.2627451  0.27058825 0.3019608 ]\n",
      "   [0.23137257 0.27058825 0.3019608 ]\n",
      "   [0.08627451 0.08627451 0.08627451]]\n",
      "\n",
      "  [[0.6392157  0.6509804  0.654902  ]\n",
      "   [0.6431373  0.654902   0.65882355]\n",
      "   [0.6509804  0.65882355 0.6627451 ]\n",
      "   ...\n",
      "   [0.05490196 0.05490196 0.05490196]\n",
      "   [0.33333334 0.27058825 0.0509804 ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.6431373  0.654902   0.65882355]\n",
      "   [0.64705884 0.654902   0.6627451 ]\n",
      "   [0.6509804  0.65882355 0.6627451 ]\n",
      "   ...\n",
      "   [0.08627451 0.08627451 0.08627451]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0509804  0.0509804  0.0509804 ]\n",
      "   [0.0509804  0.0509804  0.0509804 ]\n",
      "   [0.0509804  0.0509804  0.0509804 ]\n",
      "   ...\n",
      "   [0.10980393 0.10980393 0.13333334]\n",
      "   [0.10980393 0.10980393 0.13333334]\n",
      "   [0.10980393 0.10980393 0.13333334]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.0509804  0.0509804  0.0509804 ]\n",
      "   ...\n",
      "   [0.10980393 0.13333334 0.13333334]\n",
      "   [0.10980393 0.10980393 0.13333334]\n",
      "   [0.10980393 0.10980393 0.13333334]]\n",
      "\n",
      "  [[0.         0.0509804  0.0509804 ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.10980393 0.10980393 0.13333334]\n",
      "   [0.10980393 0.13333334 0.13333334]\n",
      "   [0.10980393 0.10980393 0.10980393]]]\n",
      "\n",
      "\n",
      " [[[0.6156863  0.627451   0.63529414]\n",
      "   [0.6156863  0.627451   0.63529414]\n",
      "   [0.6156863  0.627451   0.63529414]\n",
      "   ...\n",
      "   [0.5921569  0.60784316 0.6117647 ]\n",
      "   [0.5882353  0.60784316 0.60784316]\n",
      "   [0.5882353  0.6039216  0.60784316]]\n",
      "\n",
      "  [[0.6156863  0.627451   0.63529414]\n",
      "   [0.6156863  0.627451   0.63529414]\n",
      "   [0.6117647  0.627451   0.6313726 ]\n",
      "   ...\n",
      "   [0.5882353  0.6039216  0.60784316]\n",
      "   [0.5921569  0.60784316 0.6117647 ]\n",
      "   [0.5921569  0.60784316 0.60784316]]\n",
      "\n",
      "  [[0.6156863  0.627451   0.63529414]\n",
      "   [0.61960787 0.6313726  0.6392157 ]\n",
      "   [0.6156863  0.627451   0.63529414]\n",
      "   ...\n",
      "   [0.59607846 0.60784316 0.6156863 ]\n",
      "   [0.5921569  0.60784316 0.6117647 ]\n",
      "   [0.5921569  0.60784316 0.6117647 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0509804  0.0509804  0.08627451]\n",
      "   [0.0509804  0.08627451 0.08627451]\n",
      "   [0.08627451 0.08627451 0.08627451]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.0509804  0.0509804  0.08627451]\n",
      "   [0.0509804  0.0509804  0.0509804 ]\n",
      "   [0.0509804  0.0509804  0.0509804 ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.08627451 0.08627451 0.08627451]\n",
      "   [0.0509804  0.0509804  0.0509804 ]\n",
      "   [0.08627451 0.08627451 0.08627451]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.5529412  0.5019608  0.46274513]\n",
      "   [0.5529412  0.5019608  0.46274513]\n",
      "   [0.5568628  0.5058824  0.4666667 ]\n",
      "   ...\n",
      "   [0.5764706  0.5176471  0.4666667 ]\n",
      "   [0.5764706  0.5176471  0.4666667 ]\n",
      "   [0.57254905 0.5137255  0.46274513]]\n",
      "\n",
      "  [[0.5529412  0.5019608  0.46274513]\n",
      "   [0.5529412  0.5019608  0.46274513]\n",
      "   [0.5568628  0.5058824  0.4666667 ]\n",
      "   ...\n",
      "   [0.5803922  0.5176471  0.4666667 ]\n",
      "   [0.5764706  0.5176471  0.4666667 ]\n",
      "   [0.5803922  0.52156866 0.4666667 ]]\n",
      "\n",
      "  [[0.5568628  0.5058824  0.4666667 ]\n",
      "   [0.5568628  0.5058824  0.4666667 ]\n",
      "   [0.5568628  0.5058824  0.4666667 ]\n",
      "   ...\n",
      "   [0.5803922  0.52156866 0.4666667 ]\n",
      "   [0.5803922  0.52156866 0.47058827]\n",
      "   [0.5803922  0.52156866 0.4666667 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.2392157  0.18039216 0.16470589]\n",
      "   [0.23137257 0.16470589 0.14901961]\n",
      "   [0.21960786 0.14901961 0.14901961]\n",
      "   ...\n",
      "   [0.14901961 0.08627451 0.08627451]\n",
      "   [0.16470589 0.10980393 0.10980393]\n",
      "   [0.20784315 0.14901961 0.13333334]]\n",
      "\n",
      "  [[0.19607845 0.13333334 0.13333334]\n",
      "   [0.18039216 0.13333334 0.10980393]\n",
      "   [0.18039216 0.13333334 0.10980393]\n",
      "   ...\n",
      "   [0.10980393 0.0509804  0.0509804 ]\n",
      "   [0.13333334 0.08627451 0.08627451]\n",
      "   [0.13333334 0.08627451 0.08627451]]\n",
      "\n",
      "  [[0.14901961 0.08627451 0.08627451]\n",
      "   [0.14901961 0.10980393 0.08627451]\n",
      "   [0.13333334 0.08627451 0.08627451]\n",
      "   ...\n",
      "   [0.08627451 0.0509804  0.0509804 ]\n",
      "   [0.10980393 0.08627451 0.0509804 ]\n",
      "   [0.10980393 0.0509804  0.0509804 ]]]\n",
      "\n",
      "\n",
      " [[[0.47058827 0.53333336 0.5921569 ]\n",
      "   [0.47058827 0.53333336 0.5921569 ]\n",
      "   [0.47058827 0.5294118  0.5921569 ]\n",
      "   ...\n",
      "   [0.4666667  0.53333336 0.6       ]\n",
      "   [0.46274513 0.5294118  0.59607846]\n",
      "   [0.45882356 0.5294118  0.59607846]]\n",
      "\n",
      "  [[0.48235297 0.5411765  0.6       ]\n",
      "   [0.47450984 0.53333336 0.59607846]\n",
      "   [0.47058827 0.53333336 0.5921569 ]\n",
      "   ...\n",
      "   [0.47058827 0.5372549  0.6       ]\n",
      "   [0.4666667  0.53333336 0.6       ]\n",
      "   [0.46274513 0.5294118  0.59607846]]\n",
      "\n",
      "  [[0.49803925 0.54901963 0.6039216 ]\n",
      "   [0.4901961  0.54509807 0.6039216 ]\n",
      "   [0.48235297 0.5411765  0.6       ]\n",
      "   ...\n",
      "   [0.4666667  0.53333336 0.6       ]\n",
      "   [0.46274513 0.5294118  0.59607846]\n",
      "   [0.46274513 0.5294118  0.59607846]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.0509804 ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.0509804  0.0509804  0.0509804 ]\n",
      "   ...\n",
      "   [0.         0.0509804  0.08627451]\n",
      "   [0.0509804  0.0509804  0.08627451]\n",
      "   [0.         0.0509804  0.0509804 ]]\n",
      "\n",
      "  [[0.0509804  0.0509804  0.0509804 ]\n",
      "   [0.         0.         0.0509804 ]\n",
      "   [0.0509804  0.0509804  0.0509804 ]\n",
      "   ...\n",
      "   [0.0509804  0.0509804  0.08627451]\n",
      "   [0.         0.0509804  0.0509804 ]\n",
      "   [0.         0.0509804  0.0509804 ]]\n",
      "\n",
      "  [[0.0509804  0.0509804  0.0509804 ]\n",
      "   [0.         0.         0.0509804 ]\n",
      "   [0.         0.0509804  0.0509804 ]\n",
      "   ...\n",
      "   [0.         0.0509804  0.0509804 ]\n",
      "   [0.0509804  0.0509804  0.0509804 ]\n",
      "   [0.         0.0509804  0.0509804 ]]]\n",
      "\n",
      "\n",
      " [[[0.25882354 0.37647063 0.5372549 ]\n",
      "   [0.2509804  0.37647063 0.5372549 ]\n",
      "   [0.25882354 0.38431376 0.5411765 ]\n",
      "   ...\n",
      "   [0.29411766 0.38823533 0.52156866]\n",
      "   [0.28627452 0.38431376 0.5176471 ]\n",
      "   [0.28627452 0.38431376 0.5176471 ]]\n",
      "\n",
      "  [[0.25882354 0.38431376 0.53333336]\n",
      "   [0.25882354 0.37647063 0.5372549 ]\n",
      "   [0.25882354 0.37647063 0.5372549 ]\n",
      "   ...\n",
      "   [0.29411766 0.38431376 0.5176471 ]\n",
      "   [0.29411766 0.38823533 0.5176471 ]\n",
      "   [0.29411766 0.38431376 0.5176471 ]]\n",
      "\n",
      "  [[0.27058825 0.38431376 0.5294118 ]\n",
      "   [0.27058825 0.38431376 0.5372549 ]\n",
      "   [0.25882354 0.38431376 0.5372549 ]\n",
      "   ...\n",
      "   [0.3019608  0.39607847 0.5176471 ]\n",
      "   [0.3019608  0.38823533 0.5176471 ]\n",
      "   [0.3019608  0.38823533 0.5176471 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.0509804 ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.0509804 ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.0509804 ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.0509804 ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]], shape=(64, 192, 256, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  [[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  [[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]]\n",
      "\n",
      "\n",
      " [[[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 9]\n",
      "   [ 9]\n",
      "   [ 9]]\n",
      "\n",
      "  [[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 9]\n",
      "   [ 9]\n",
      "   [ 9]]\n",
      "\n",
      "  [[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 9]\n",
      "   [ 9]\n",
      "   [ 9]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]]\n",
      "\n",
      "\n",
      " [[[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  [[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  [[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  [[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  [[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]]\n",
      "\n",
      "\n",
      " [[[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  [[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  [[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]]\n",
      "\n",
      "\n",
      " [[[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  [[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  [[ 0]\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   ...\n",
      "   [ 0]\n",
      "   [ 0]\n",
      "   [ 0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]\n",
      "\n",
      "  [[10]\n",
      "   [10]\n",
      "   [10]\n",
      "   ...\n",
      "   [10]\n",
      "   [10]\n",
      "   [10]]]], shape=(64, 192, 256, 1), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "for i , j in tuple(train)[:2]:\n",
    "    print(i)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model_history1 = model.fit(train, validation_data=val, epochs=1, callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history1.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
