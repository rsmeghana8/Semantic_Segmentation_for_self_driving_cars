{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/Ubuntu/meg/mlprojects/Semantic_Segmentation_for_self_driving_cars'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 13:16:37.078942: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.components.data_preparation import DataIngestion\n",
    "from src.components.data_preprocesing import DataPreprocessing\n",
    "from src.components.callbacks import PrepareCallback\n",
    "from src.components.model import PrepareModel\n",
    "from src.config.configuration import ConfigurationManager\n",
    "from src.entity.config_entity import DataIngestionConfig, PrepareCallbackConfig, PrepareModelConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.entity.config_entity import DataPreprocessingConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-26 13:16:56,281: INFO: common: yaml fileconfig.yamlloaded Successfully]\n",
      "[2023-09-26 13:16:56,283: INFO: common: yaml fileparams.yamlloaded Successfully]\n",
      "[2023-09-26 13:16:56,292: INFO: common: created directory at:artifacts]\n",
      "[2023-09-26 13:16:56,293: INFO: common: created directory at:/media/Ubuntu/meg/mlprojects/Semantic_Segmentation_for_self_driving_cars/archive]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 13:16:56.348541: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-09-26 13:16:56.631972: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [5000]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-09-26 13:16:56.632315: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [5000]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_data_config = config.get_data_ingestion_config()\n",
    "\n",
    "    prepare_dataset = DataIngestion(config=prepare_data_config)\n",
    "    imgs_list, masks_list = prepare_dataset.prepare_data()\n",
    "\n",
    "    preprocessing_config = config.get_data_processing_config()\n",
    "    preprocessing = DataPreprocessing(preprocessing_config,imgs_list, masks_list)\n",
    "    train, val = preprocessing.data_preprocessing()\n",
    "\n",
    "except Exception as e:\n",
    "    raise e\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-26 13:17:28,276: INFO: common: yaml fileconfig.yamlloaded Successfully]\n",
      "[2023-09-26 13:17:28,280: INFO: common: yaml fileparams.yamlloaded Successfully]\n",
      "[2023-09-26 13:17:28,281: INFO: common: created directory at:artifacts]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 192, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 192, 256, 32  896         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 192, 256, 32  128        ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 192, 256, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 192, 256, 32  9248        ['leaky_re_lu[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 192, 256, 32  128        ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 192, 256, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 96, 128, 32)  0           ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 96, 128, 64)  18496       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 96, 128, 64)  256        ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 96, 128, 64)  0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 96, 128, 64)  36928       ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 96, 128, 64)  256        ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 96, 128, 64)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 48, 64, 64)  0           ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 48, 64, 128)  73856       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 48, 64, 128)  512        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 48, 64, 128)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 48, 64, 128)  147584      ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 48, 64, 128)  512        ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 48, 64, 128)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 24, 32, 128)  0          ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 24, 32, 256)  295168      ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 24, 32, 256)  1024       ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 24, 32, 256)  0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 24, 32, 256)  590080      ['leaky_re_lu_6[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 24, 32, 256)  1024       ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 24, 32, 256)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 24, 32, 256)  0           ['leaky_re_lu_7[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 12, 16, 256)  0          ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 12, 16, 512)  1180160     ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 12, 16, 512)  2048       ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 12, 16, 512)  0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 12, 16, 512)  2359808     ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 12, 16, 512)  2048       ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 12, 16, 512)  0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 12, 16, 512)  0           ['leaky_re_lu_9[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 24, 32, 256)  1179904    ['dropout_1[0][0]']              \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 24, 32, 512)  0           ['conv2d_transpose[0][0]',       \n",
      "                                                                  'dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 24, 32, 256)  1179904     ['tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 24, 32, 256)  1024       ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 24, 32, 256)  0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 24, 32, 256)  590080      ['leaky_re_lu_10[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 24, 32, 256)  1024       ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 24, 32, 256)  0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 48, 64, 128)  295040     ['leaky_re_lu_11[0][0]']         \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)       (None, 48, 64, 256)  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                                                  'leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 48, 64, 128)  295040      ['tf.concat_1[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 48, 64, 128)  512        ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)     (None, 48, 64, 128)  0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 48, 64, 128)  147584      ['leaky_re_lu_12[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 48, 64, 128)  512        ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)     (None, 48, 64, 128)  0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 96, 128, 64)  73792      ['leaky_re_lu_13[0][0]']         \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " tf.concat_2 (TFOpLambda)       (None, 96, 128, 128  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                )                                 'leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 96, 128, 64)  73792       ['tf.concat_2[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 96, 128, 64)  256        ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_14 (LeakyReLU)     (None, 96, 128, 64)  0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 96, 128, 64)  36928       ['leaky_re_lu_14[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 96, 128, 64)  256        ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_15 (LeakyReLU)     (None, 96, 128, 64)  0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 192, 256, 32  18464      ['leaky_re_lu_15[0][0]']         \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " tf.concat_3 (TFOpLambda)       (None, 192, 256, 64  0           ['conv2d_transpose_3[0][0]',     \n",
      "                                )                                 'leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 192, 256, 32  18464       ['tf.concat_3[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 192, 256, 32  128        ['conv2d_16[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_16 (LeakyReLU)     (None, 192, 256, 32  0           ['batch_normalization_16[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 192, 256, 32  9248        ['leaky_re_lu_16[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 192, 256, 32  128        ['conv2d_17[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_17 (LeakyReLU)     (None, 192, 256, 32  0           ['batch_normalization_17[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 192, 256, 32  9248        ['leaky_re_lu_17[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 192, 256, 32  128        ['conv2d_18[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_18 (LeakyReLU)     (None, 192, 256, 32  0           ['batch_normalization_18[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 192, 256, 1)  33          ['leaky_re_lu_18[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 192, 256, 1)  4          ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_19 (LeakyReLU)     (None, 192, 256, 1)  0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,651,653\n",
      "Trainable params: 8,645,699\n",
      "Non-trainable params: 5,954\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_model_config = config.get_prepare_model_config()\n",
    "    prepare_model = PrepareModel(prepare_model_config)\n",
    "    model = prepare_model.unet_model()\n",
    "    model.summary()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainingConfig:\n",
    "    epochs: int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.constants import *\n",
    "from src.utils.common import read_yaml, create_directories\n",
    "from box import ConfigBox\n",
    "from src import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath= PARAMS_FILE_PATH) :\n",
    "                 \n",
    "        self.config = read_yaml(config_filepath),\n",
    "        self.params = read_yaml(params_filepath),\n",
    "        self.config= ConfigBox(self.config[0]) # configbox is returning tuple so to avoid it we are again applying configbox to the dictionary at index 0\n",
    "        self.params= ConfigBox(self.params[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_prepare_training_config(self)-> ModelTrainingConfig:\n",
    "        config = self.params\n",
    "\n",
    "\n",
    "\n",
    "        prepare_training_config = PrepareModelConfig(\n",
    "                            img_height = config.img_height,\n",
    "                            img_width = config.img_width,\n",
    "                            num_channels= config.num_channels,\n",
    "                            epochs = config.EPOCHS)\n",
    "        return prepare_training_config\n",
    "\n",
    "    def get_prepare_callback_config(self)-> PrepareCallbackConfig:\n",
    "        config = self.config.prepare_callbacks\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "\n",
    "        create_directories([ \n",
    "                            Path(config.checkpoint_model_filepath),\n",
    "                            Path(config.tensorboard_root_log_dir)  ])\n",
    "\n",
    "        prepare_callback_config = PrepareCallbackConfig(\n",
    "            root_dir = Path(config.root_dir),\n",
    "            tensorboard_root_log_dir = Path(config.tensorboard_root_log_dir),\n",
    "            checkpoint_model_filepath= Path(config.checkpoint_model_filepath)\n",
    "    \n",
    "        )\n",
    "        return prepare_callback_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self,config: ModelTrainingConfig):\n",
    "        self.config = config\n",
    "        \n",
    "\n",
    "    def train(self, model, callbacklist, data):\n",
    "        self.model = model((self.config.img_height,self.config.img_width, self.config.num_channels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-26 13:17:39,572: INFO: common: yaml fileconfig.yamlloaded Successfully]\n",
      "[2023-09-26 13:17:39,574: INFO: common: yaml fileparams.yamlloaded Successfully]\n",
      "[2023-09-26 13:17:39,575: INFO: common: created directory at:artifacts]\n",
      "[2023-09-26 13:17:39,575: INFO: common: created directory at:artifacts/callbacks]\n",
      "[2023-09-26 13:17:39,576: INFO: common: created directory at:artifacts/callbacks/checkpoints]\n",
      "[2023-09-26 13:17:39,576: INFO: common: created directory at:artifacts/callbacks/tensorboard_log_dir]\n",
      "artifacts/callbacks/tensorboard_log_dir/tb_logs_at_2023-09-26-13-17-39\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_callbacks_config= config.get_prepare_callback_config()\n",
    "    prepare_callbacks= PrepareCallback(config = prepare_callbacks_config)\n",
    "    callback_list = prepare_callbacks.get_tb_ckpt_callbacks()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.src.callbacks.TensorBoard at 0x7fe9361ad1f0>,\n",
       " <keras.src.callbacks.ModelCheckpoint at 0x7fe9d84f6340>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model1 = model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "BUFFER_SIZE = 500\n",
    "BATCH_SIZE = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/media/Ubuntu/meg/mlprojects/Semantic_Segmentation_for_self_driving_cars/research/05_training.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/Ubuntu/meg/mlprojects/Semantic_Segmentation_for_self_driving_cars/research/05_training.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tf\u001b[39m.\u001b[39m__version__\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 13:17:52.591702: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [5000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-09-26 13:17:52.592094: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [5000]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model_history1 = model.fit(train, validation_data=val, epochs=1, callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
